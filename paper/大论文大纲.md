论文题目建议
题目： 面向小程序隐私合规检测的自动化框架 MiniEval 设计与研究
￼

#### 第一章 绪论 (Introduction)

• 1.1 研究背景与挑战
• 移动应用隐私合规现状与“不授权即停用”等新型违规问题。
• 现有静态分析工具的语义理解短板：难以判断“声明合理性” 
• 1.2 国内外研究现状
• 程序分析在隐私检测中的应用（Taint Analysis, UI Automation）。
• LLM 在软件工程与合规审计中的应用。
• 1.3 本文主要贡献

#### 第二章 MiniEval 框架设计与行为违规检测

(本章保持不变，作为 MiniEval 的“骨架”与静态分析技术核心)
• 2.1 MiniEval 系统架构
• 包含三大核心组件：行为违规检测、目的合理性分类（本章仅做功能性介绍，技术实现在第三章）、隐私风险评估 
• 2.2 间接违规 (Indirect Violation) 检测技术
定义： 基于控制依赖的强制功能阻塞 
查看来源详情。打开侧边栏。
算法实现： 提出控制感知隐私流分析 (CAPFA)，构建 CEAFG 图模型，追踪从 API 调用到 UI 阻塞点的完整路径 
• 2.3 场景一致性与直接违规检测
• 结合静态代码分析与 LLM 语义理解，验证实际场景与声明的一致性 

#### 第三章 隐私声明目的合理性分类

• 3.1 隐私声明合理性的定义与挑战
任务定义： 对不合理声明进行分类 
• 技术挑战： 通用模型缺乏法律/合规领域的隐性知识；在线推理成本高昂。
• 3.2 阶段一：基于深度提示工程 (Prompt Engineering) 的性能激发
策略设计： 引入负面锚点（Negative Anchors）与对比性示例（Contrastive Examples）界定模糊边界 
• 思维链 (CoT) 引导： 强制模型先生成判别依据（Rationale），再输出标签，提升逻辑推理的稳定性。
• 实验分析： 验证 Prompt 优化对基座模型（如 Qwen-Plus）的性能提升上限。
• 3.3 阶段二：基于指令微调 (SFT) 的领域能力注入
• 数据构建： 基于 MiniEval 标注数据构建 (Instruction, Input, Output) 指令集。
• 微调策略： 采用 LoRA/QLoRA 技术对开源基座（如 Llama-3-8B）进行参数高效微调。
• 效果验证： 解决通用模型在“可替代冗余”等高难度类别上的领域知识缺失问题。
• 3.4 阶段三：基于模型蒸馏 (Distillation) 的工程落地
• 教师-学生架构： 使用 SFT 后的模型作为 Teacher，指导 1.5B/3B 参数量的 Student 模型。
• 性能评估：

#### 第四章 隐私风险量化评估与生态实证分析

(基于前两章的技术成果——“行为检测结果”和“声明分类结果”，进行综合评估)
• 4.1 隐私风险多维量化模型
评分公式： 整合数据敏感度 ()、行为违规因子 () 和声明不合理因子 () 
查看来源详情。打开侧边栏。
• 关键输入更新： 将第三章优化后的高精度 LLM 分类结果代入公式，消除因模型误判导致的评分偏差。
• 4.2 数据驱动的风险分级
• 采用 K-Means 聚类算法替代人工阈值，客观划分风险等级（Low, Moderate, High, Severe） 
• 4.3 大规模生态实证
• 对 15,000+ 个真实小程序进行全量检测。
• 发现与洞察： 揭示高风险应用在电商、医疗等领域的分布规律，验证优化后框架在大规模场景下的鲁棒性。

#### 第五章 总结与展望

• 5.1 论文总结
• 5.2 未来工作
• 探索多模态大模型在 UI 截图合规检测中的应用。
• 进一步研究针对第三方开发框架（如 Uni-app）的深度静态分析技术。