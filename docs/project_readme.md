# 小程序隐私声明语句分类实验

本项目用于**小程序隐私声明文本的自动分类实验**，重点分析声明中各语句在**必要性（Necessity）**与**清晰性（Clarity）**两个维度上的判定效果，并对多种模型与方法进行系统对比。

实验目标不仅在于分类性能本身，还在于分析不同技术路线在**一致性、可解释性与工程可落地性**方面的差异，为后续隐私合规分析与自动化审计提供支撑。

---

## 一、研究背景与问题定义

小程序隐私声明通常由自然语言描述构成，存在以下现实问题：

* 声明语句是否**明确表达**了数据使用目的（清晰性问题）
* 声明中涉及的数据收集/使用是否对当前功能**必要**（必要性问题）
* 不同自动化方法对同一语句的判断是否一致

本项目将声明语句视为分类对象，对每条语句进行如下判定：

* **必要性（Necessity）**：

  * 必要 / 非必要
* **清晰性（Clarity）**：

  * 清晰 / 不清晰

这是一个**监督式文本分类问题**，同时也是一个适合引入大模型与蒸馏技术的实验场景。

---

## 二、数据集说明

* 数据来源：真实小程序隐私声明文本
* 数据规模：**1000+ 条人工标注语句**
* 标注内容：

  * 语句级别
  * 每条语句同时标注：

    * 必要性标签
    * 清晰性标签

数据被划分为：

* 训练集
* 验证集
* 测试集

（具体比例可在配置中调整）

---

## 三、实验方法总览

本项目对比了四条主要技术路线：

1. **传统预训练模型（BERT 类）**
2. **直接使用 LLM 的提示词分类（Prompting）**
3. **STF（Self-Training / Structured Thought Framework）增强的 LLM 分类**
4. **基于 STF 结果的模型蒸馏（Distillation）**

并在此基础上分析：

* 不同方法之间的分类一致性
* 蒸馏前后模型行为的变化

---

## 四、实验流程说明

### 4.1 总体流程

```text
人工标注数据
      ↓
BERT 基线训练
      ↓
LLM Prompt 分类
      ↓
STF 增强推理与分类
      ↓
蒸馏数据构建（STF 输出）
      ↓
学生模型训练（Distillation）
      ↓
一致性与性能评估
```

---

### 4.2 BERT 类模型实验

* 模型：BERT / RoBERTa 等
* 训练方式：

  * 标准监督学习
  * 输入：单条声明语句
  * 输出：

    * 必要性分类
    * 清晰性分类（可为多头或独立模型）

作为：

* 传统 NLP 基线
* 与大模型方法的对照组

---

### 4.3 LLM 提示词分类（Prompting）

* 使用大语言模型直接进行分类
* 核心方式：

  * 精心设计的提示词（Prompt）
  * 明确分类标准与判定依据

特点：

* 无需训练
* 强依赖提示词质量
* 易出现判断不稳定问题

---

### 4.4 STF 增强的 LLM 分类

STF 用于引导模型进行**结构化、自我约束的推理**，而非直接给出结论。

典型流程包括：

1. 语句语义解析
2. 数据类型与使用目的识别
3. 必要性与清晰性分别推理
4. 给出最终分类结论

STF 的作用：

* 提高分类一致性
* 减少“拍脑袋式”判断
* 为蒸馏提供高质量软标签

---

### 4.5 模型蒸馏（Distillation）

* **教师模型**：STF 后的大语言模型
* **学生模型**：轻量化分类模型（如 BERT / 小模型 Transformer）

蒸馏目标：

* 继承 STF-LLM 的判断模式
* 降低推理成本
* 提高工程可部署性

蒸馏数据来源：

* STF 输出的分类结果
* 可包含：

  * 最终标签
  * 中间判定信息（如可选）

---

## 五、一致性分析

本项目不仅评估准确率，还重点关注：

* BERT vs LLM
* LLM Prompt vs STF
* STF vs 蒸馏模型

一致性分析指标包括：

* 标签一致率
* 冲突样本分析
* 不一致案例的语义特征总结

该部分用于回答：

> 不同技术路线是否在“隐私判断”这一任务上形成共识？


